{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from imutils import perspective\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sudoku_solver as ss\n",
    "model = tf.keras.models.load_model('digitRecognizer-v2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image and apply gaussian blur\n",
    "img = cv.imread('sudoku.jfif')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "gblur = cv.GaussianBlur(gray, (9,9), 0)\n",
    "cv.imshow('gblur', gblur)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply edge detection, remove lighter lines and dilate edges\n",
    "thresh = cv.adaptiveThreshold(gblur, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 11, 2)\n",
    "cv.imshow('thresh', thresh)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find contours on the image\n",
    "contours, _ = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the 4-sided contour with largest area and map it to a square of 600x600\n",
    "max_area = 0\n",
    "max_rect = 0\n",
    "for contour in contours:\n",
    "    approx = cv.approxPolyDP(contour, 0.01*cv.arcLength(contour, True), True)\n",
    "    if len(approx) == 4:\n",
    "        area = cv.contourArea(approx)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_rect = approx\n",
    "pts1 = np.squeeze(max_rect).tolist()\n",
    "pts1 = np.float32(pts1)\n",
    "cv.circle(img, tuple(pts1[0]), 5, (0,255,0), -1)\n",
    "cv.circle(img, tuple(pts1[1]), 5, (0,255,0), -1)\n",
    "cv.circle(img, tuple(pts1[2]), 5, (0,255,0), -1)\n",
    "cv.circle(img, tuple(pts1[3]), 5, (0,255,0), -1)\n",
    "pts1 = perspective.order_points(pts1)\n",
    "pts2 = np.float32([[0,0], [450, 0], [450,450], [0,450]])\n",
    "matrix = cv.getPerspectiveTransform(pts1, pts2)\n",
    "result = cv.warpPerspective(gray, matrix, (450, 450))\n",
    "color_result = cv.warpPerspective(img, matrix, (450, 450))\n",
    "\n",
    "cv.imshow('result', result)\n",
    "cv.imshow('contours', gray)\n",
    "cv.imshow('image', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top-left coordinates of each square\n",
    "squares = []\n",
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        p1 = (j*50, i*50)\n",
    "        squares.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the square\n",
    "thresh = cv.adaptiveThreshold(result, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 11, 5)\n",
    "roi = []\n",
    "color_roi = []\n",
    "for x, y in squares:\n",
    "    roi.append(cv.morphologyEx(thresh[y+5:y+45, x+5:x+45], cv.MORPH_OPEN, np.ones((2,2), np.uint8)))\n",
    "    color_roi.append(color_result[y+5:y+45, x+5:x+45])\n",
    "%matplotlib qt\n",
    "for i in range(81):\n",
    "    plt.subplot(9, 9, i+1), plt.imshow(color_roi[i], cmap='gray')\n",
    "    plt.title(i)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the number of white pixels is greater than threshold value then they contain digits\n",
    "threshold = 50\n",
    "digits = []\n",
    "idx = []\n",
    "for i in range(81):\n",
    "    num_white_pixels = np.sum(roi[i][10:30, 10:30] == 255)\n",
    "    if num_white_pixels > threshold:\n",
    "        digits.append(cv.bitwise_not(roi[i]).reshape(40,40,1))\n",
    "        idx.append(i)\n",
    "for digit in digits:\n",
    "   cv.imshow('', digit)\n",
    "   cv.waitKey(0)\n",
    "   cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for digit in digits:\n",
    "    predictions.append(int(model.predict_classes(digit.reshape(-1,40,40,1)/255.)))\n",
    "plt.figure()\n",
    "for i in range(len(digits)):\n",
    "    plt.subplot(6, 6, i+1), plt.imshow(digits[i].reshape(40,40), cmap='gray')\n",
    "    plt.title(predictions[i])\n",
    "    plt.axis('off')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 6 8 1 7 2 9 3 5]\n",
      " [1 9 3 6 8 5 4 7 2]\n",
      " [7 5 2 9 4 3 8 6 1]\n",
      " [3 7 6 5 9 4 2 1 8]\n",
      " [2 1 5 8 3 7 6 9 4]\n",
      " [8 4 9 2 6 1 3 5 7]\n",
      " [6 2 7 4 5 9 1 8 3]\n",
      " [9 3 1 7 2 8 5 4 6]\n",
      " [5 8 4 3 1 6 7 2 9]]\n"
     ]
    }
   ],
   "source": [
    "grid = ss.build_grid(predictions, idx)\n",
    "if ss.solve(grid):\n",
    "    print(grid)\n",
    "else:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(81):\n",
    "    if i in idx: continue\n",
    "    row = int(i/9)\n",
    "    col = i%9\n",
    "    x, y = squares[i]\n",
    "    cv.putText(color_result[y+5:y+45, x+5:x+45], f'{grid[row][col]}', (10,30), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('final', color_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv.warpPerspective(color_result, matrix, img.shape[:2][::-1], img, cv.WARP_INVERSE_MAP, borderMode=cv.BORDER_TRANSPARENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('final_image', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "539.667px",
    "left": "429.333px",
    "right": "20px",
    "top": "-8px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
